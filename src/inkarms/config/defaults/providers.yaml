# InkArms Provider Configuration
# This file contains default provider and model definitions.
# Do not edit this file directly.
# To override or add providers, create a 'providers.yaml' file in ~/.inkarms/

providers:
  anthropic:
    id: "anthropic"
    name: "Anthropic Claude"
    description: "Recommended - best for coding"
    env_var: "ANTHROPIC_API_KEY"
    default_model: "claude-sonnet-4-5-20250929"
    default_context_window: 200000
    api_models_endpoint: "https://api.anthropic.com/v1/models"
    api_models_mapper: "anthropic"
    models:
      - id: "claude-sonnet-4-5-20250929"
        name: "Claude Sonnet 4.5"
        description: "Latest, fastest, most capable"
        context_window: 1000000
        cost_per_m_in: 3
        cost_per_m_out: 15
        recommended: true
      - id: "claude-opus-4-5-20251101"
        name: "Claude Opus 4.5"
        description: "Maximum capability"
        context_window: 200000
      - id: "claude-haiku-4-5-20251001"
        name: "Claude Haiku 4.5"
        description: "Fast and efficient"
        context_window: 200000
      - id: "claude-sonnet-4-20250514"
        name: "Claude Sonnet 4"
        description: "Previous generation"
        context_window: 1000000
        cost_per_m_in: 3
        cost_per_m_out: 15
      - id: "claude-opus-4-20250514"
        name: "Claude Opus 4"
        description: "Previous generation capable"
        context_window: 200000
      - id: "claude-3-5-sonnet-20241022"
        name: "Claude 3.5 Sonnet"
        description: "Previous generation"
        context_window: 200000
        deprecated: true
      - id: "claude-3-opus-20240229"
        name: "Claude 3 Opus"
        description: "Legacy capable model"
        context_window: 200000
        deprecated: true
      - id: "claude-3-sonnet-20240229"
        name: "Claude 3 Sonnet"
        description: "Legacy balanced model"
        context_window: 200000
        deprecated: true
      - id: "claude-3-haiku-20240307"
        name: "Claude 3 Haiku"
        description: "Fastest legacy model"
        context_window: 200000
        deprecated: true

  openai:
    id: "openai"
    name: "OpenAI GPT"
    description: "GPT-4o and GPT-4 Turbo"
    env_var: "OPENAI_API_KEY"
    default_model: "gpt-4o"
    default_context_window: 128000
    models:
      - id: "gpt-4o"
        name: "GPT-4o"
        description: "Latest multimodal"
        context_window: 128000
        recommended: true
      - id: "gpt-4o-mini"
        name: "GPT-4o Mini"
        description: "Efficient and fast"
        context_window: 128000
      - id: "gpt-4-turbo"
        name: "GPT-4 Turbo"
        description: "Fast and capable"
        context_window: 128000
      - id: "gpt-4"
        name: "GPT-4"
        description: "Legacy model"
        context_window: 8192
        deprecated: true
      - id: "gpt-3.5-turbo"
        name: "GPT-3.5 Turbo"
        description: "Legacy fast model"
        context_window: 16385
        deprecated: true
      - id: "o3-mini"
        name: "o3-mini"
        description: "Latest reasoning model"
        context_window: 128000

  google:
    id: "google"
    name: "Google Gemini"
    description: "Gemini Pro & Flash models"
    env_var: "GOOGLE_API_KEY"
    default_model: "gemini-2.5-pro"
    default_context_window: 1048576
    api_models_endpoint: "https://generativelanguage.googleapis.com/v1beta/models"
    api_models_mapper: "google"
    models:
      - id: "gemini-2.5-pro"
        name: "Gemini 2.5 Pro"
        description: "Best capability"
        context_window: 1048576
        recommended: true
      - id: "gemini-2.5-flash"
        name: "Gemini 2.5 Flash"
        description: "Fast and efficient"
        context_window: 1048576
      - id: "gemini-3-pro"
        name: "Gemini 3 Pro"
        description: "Next-gen preview"
        context_window: 1048576
      - id: "gemini-3-flash"
        name: "Gemini 3 Flash"
        description: "Next-gen fast preview"
        context_window: 1048576
      - id: "gemini-2.5-flash-lite"
        name: "Gemini 2.5 Flash-Lite"
        description: "Cost effective"
        context_window: 1048576
      - id: "gemini-2.0-flash"
        name: "Gemini 2.0 Flash"
        description: "Previous generation fast"
        context_window: 1048576
      - id: "gemini-2.0-flash-lite"
        name: "Gemini 2.0 Flash-Lite"
        description: "Previous generation efficient"
        context_window: 1048576
      - id: "gemini-1.5-pro"
        name: "Gemini 1.5 Pro"
        description: "Legacy large context"
        context_window: 2097152
        deprecated: true
      - id: "gemini-1.5-flash"
        name: "Gemini 1.5 Flash"
        description: "Legacy fast"
        context_window: 1048576
        deprecated: true
      - id: "gemini-pro"
        name: "Gemini Pro 1.0"
        description: "Discontinued"
        context_window: 32000
        deprecated: true

  github_copilot:
    id: "github_copilot"
    name: "GitHub Copilot"
    description: "Use existing Copilot subscription"
    env_var: "GITHUB_TOKEN"
    default_model: "gpt-4o"
    default_context_window: 128000
    models:
      - id: "gpt-4o"
        name: "GPT-4o"
        description: "Via Copilot"
        context_window: 128000
        recommended: true
      - id: "claude-sonnet-4.5"
        name: "Claude Sonnet 4.5"
        description: "Via Copilot"
        context_window: 200000
      - id: "gpt-5.2"
        name: "GPT-5.2"
        description: "Latest via Copilot"
        context_window: 128000
      - id: "gpt-5.2-codex"
        name: "GPT-5.2 Codex"
        description: "Code focused"
        context_window: 128000
      - id: "claude-opus-4.5"
        name: "Claude Opus 4.5"
        description: "Via Copilot"
        context_window: 200000

  ollama:
    id: "ollama"
    name: "Ollama"
    description: "Local models, no API key needed"
    is_local: true
    default_model: "llama3.3"
    default_context_window: 32000
    models:
      - id: "llama3.3"
        name: "Llama 3.3"
        description: "Latest state of the art open model"
        context_window: 128000
        recommended: true
      - id: "llama3.2"
        name: "Llama 3.2"
        description: "Efficient open model"
        context_window: 128000
      - id: "mistral"
        name: "Mistral"
        description: "Fast and efficient"
        context_window: 32000
      - id: "codellama"
        name: "Code Llama"
        description: "Specialized for code"
        context_window: 16384
